{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import TrainWrapper\n",
    "config = \"/home/anubis/memdir/diploma/diff_unlearn/model/config.json\"\n",
    "save = \"/home/anubis/memdir/diploma/diff_unlearn/model/model_fromscratch\"\n",
    "\n",
    "with open(config, \"r\") as fd:\n",
    "    config = json.load(fd)\n",
    "\n",
    "trainer = TrainWrapper(model_save=save, unlearn_label=0, **config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlearn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from utils import UnlearnWrapper\n",
    "\n",
    "conf_path = \"/home/anubis/memdir/diploma/diff_unlearn/model_unlearn4\"\n",
    "\n",
    "for config in os.listdir(conf_path):\n",
    "    config = os.path.join(conf_path, config)\n",
    "    with open(config, \"r\") as fd:\n",
    "        conf_dict = json.load(fd)\n",
    "    \n",
    "    unlearner = UnlearnWrapper(**conf_dict)\n",
    "    unlearner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "from unet import MNIST_Unet\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2')\n",
    "\n",
    "DEVICE = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Unet()\n",
    "model.load_state_dict(torch.load(\"model_unlearn/checkpoints/500_10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(80, 1, 28, 28).to(DEVICE)\n",
    "y = torch.tensor([[i]*8 for i in range(0, 10)]).flatten().to(DEVICE)\n",
    "model.to(DEVICE)\n",
    "# Sampling loop\n",
    "for i, t in tqdm(enumerate(noise_scheduler.timesteps)):\n",
    "    with torch.no_grad():\n",
    "        residual = model(x, t, y)  # Again, note that we pass in our labels y\n",
    "\n",
    "    x = noise_scheduler.step(residual, t, x).prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(torchvision.utils.make_grid(x.detach().cpu().clip(-1, 1), nrow=8)[0], cmap='Greys')\n",
    "plt.suptitle(\"Сгенерированные изображения измененной модели\\nS=500, K=10\")\n",
    "plt.savefig(\"tests/sample_500_10.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIA Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import MIA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpts = \"model_unlearn/checkpoints\"\n",
    "batch_size = 50\n",
    "matplotlib.use(\"Agg\")\n",
    "for pt in os.listdir(ckpts):\n",
    "    for forget in [0,1]:\n",
    "        print(f\"MODEL: {pt}\")\n",
    "        models = [\"/home/anubis/memdir/diploma/diff_unlearn/model/model15.pt\"]\n",
    "        model_path = os.path.join(ckpts, pt)\n",
    "        losses = MIA(batch_size=batch_size, models=models+[model_path], forget=forget)()\n",
    "        print(losses)\n",
    "        model_names = list(losses.keys()) \n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(losses[model_names[0]], label=os.path.basename(model_names[0]))\n",
    "        plt.plot(losses[model_names[1]], label=os.path.basename(model_names[1]))\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Loss')\n",
    "        s,k = pt.split('.')[0].split('_')\n",
    "        plt.title(f'S = {s}, K = {k}')\n",
    "        plt.savefig(f\"visual/{pt.split('.')[0]}_{forget}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
